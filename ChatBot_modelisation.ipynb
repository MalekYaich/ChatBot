{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd0328fb",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">  Chatbot -modelisation. </h1>  \n",
    "</br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5f4a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import random\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('omw-1.4')\n",
    "import numpy as np\n",
    "from nltk.stem import WordNetLemmatizer# It has the ability to lemmatize.\n",
    "import tensorflow as tensorF # A multidimensional array of elements is represented by this symbol.\n",
    "from tensorflow.keras import Sequential # Sequential groups a linear stack of layers into a tf.keras.Model\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import speech_recognition as sr\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb178b60",
   "metadata": {},
   "source": [
    "## Step one: Importing libraries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddce4b9c",
   "metadata": {},
   "source": [
    "## Step two: Creating a JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed7c0b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    with open(\"data.json\", 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11417552",
   "metadata": {},
   "source": [
    "## Step three: Processing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a42d1f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(data):\n",
    "    lm = WordNetLemmatizer() #for getting words\n",
    "    # lists\n",
    "    ourClasses = []\n",
    "    newWords = []\n",
    "    documentX = []\n",
    "    documentY = []\n",
    "    # Each intent is tokenized into words and the patterns and their associated tags are added to their respective lists.\n",
    "    for intent in data[\"Intents\"]:\n",
    "        for pattern in intent[\"patterns\"]:\n",
    "            ournewTkns = nltk.word_tokenize(pattern)# tokenize the patterns\n",
    "            newWords.extend(ournewTkns)# extends the tokens\n",
    "            documentX.append(pattern)\n",
    "            documentY.append(intent[\"tag\"])\n",
    "\n",
    "\n",
    "        if intent[\"tag\"] not in ourClasses:# add unexisting tags to their respective classes\n",
    "            ourClasses.append(intent[\"tag\"])\n",
    "\n",
    "    newWords = [lm.lemmatize(word) for word in newWords if word not in string.punctuation] # set words to lowercase if not in punctuation\n",
    "    newWords = sorted(set(newWords))# sorting words\n",
    "    ourClasses = sorted(set(ourClasses))# sorting classes\n",
    "    return (newWords,ourClasses,documentX,documentY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8cf2de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Intents': [{'tag': 'age',\n",
       "   'patterns': ['كم عمرك ؟ ', 'قداش عمرك؟'],\n",
       "   'responses': ['لقد تمت برمجتي من قبل ملاك يعيش و محمد امين اللحياني يوم 1 ماي 2023 كجزء من مشروع اكاديمي.اتم اليوم اذا يومي السادس ']},\n",
       "  {'tag': 'greeting',\n",
       "   'patterns': ['صباح النور',\n",
       "    'مرحبا',\n",
       "    'سلام علیکم',\n",
       "    'أهلاً',\n",
       "    'صباح الخير',\n",
       "    'سلام'],\n",
       "   'responses': ['عسلامة، أنا الدكتور حكيم. كيفلش نجم نعاونك؟',\n",
       "    'سلام، انا الدكتور حكيم يمكنك طرح اي استشارة طبية ',\n",
       "    ' مرحبا بيك، ماهو سؤالك اليوم ؟',\n",
       "    'صباح الخير،الدكتور حكيم حاضر لاي سؤال ']},\n",
       "  {'tag': 'goodbye',\n",
       "   'patterns': ['شكرا', 'مع السلامة'],\n",
       "   'responses': ['سررت بمساعتك',\n",
       "    'اتمنى ان تكون قد استفدت من الاجابة، بااي  ']},\n",
       "  {'tag': 'name',\n",
       "   'patterns': ['ماهو اسمك؟', 'من انت؟', 'ماهي وظيفتك؟'],\n",
       "   'responses': ['أنا الدكتور حكيم، روبوت دردشة. وظيفتي هي تقديم نصائح طبية لك']},\n",
       "  {'tag': 'الامتحان',\n",
       "   'patterns': ['انا قلقة من الإمتحان',\n",
       "    'من فضلكم كيف أتخلص من التوتر والخوف في الامتحان',\n",
       "    'كيف اتغلب على توتر الامتحان ؟',\n",
       "    'لدي امتحان غدا وانا خائفة جدا',\n",
       "    'انا خائفة من الامتحان ',\n",
       "    'عند قرب الامتحان اشعر بخوف شديد و انسى كل ما راجعته'],\n",
       "   'responses': ['جرب ممارسة تمارين الاسترخاء والتنفس العميق مع تجنب الاكثار من المنبهات وتنظيم وقت الدراسة ووضع استراحة بشكل دوري بين ساعات الدراسة',\n",
       "    \"'التوتر السابق للامتحانات أمر مقبول بل وصحي، لأن لو لم يكن هناك توتر قبل الامتحان لما كان هناك حافز للمذاكرة، لكن المشكلة حين يزيد التوتر عن تحمل الشخص فيعوقه عن الاستذكار..في هذه الحالة يجب تقييمك من قبل طبيب نفسي لوصف العلاج المناسب لحالتك، وهو علاج بسيط ويمكن التوقف عنه بمجرد انتهاء الامتحانات\"]},\n",
       "  {'tag': 'ارق',\n",
       "   'patterns': ['اشعر دائما بل اختناق وأفكر دائماً بي اشياء قد تزعجني أتمنى التخلص من هاذا الشي وشكرا ؟!',\n",
       "    'لدي مشكلة في التركيز وكثيراً ما أكون سرحان ',\n",
       "    'لا استطيع النوم بشكل جيد',\n",
       "    'اعاني من اضطرابات في النوم'],\n",
       "   'responses': ['تحتاج التنظيم نمطك اليومي ومن ثم التدرب على تمارين السيطرة على النفس']},\n",
       "  {'tag': 'autre',\n",
       "   'patterns': [' '],\n",
       "   'responses': ['ممكن ان توصفي وضعك بشكل ادق',\n",
       "    'تحتاج لمراجعة اقرب عيادة نفسية لتقييم حالتك',\n",
       "    'تحتاج لمزيد من التشخيص لدى متخصص لمعرفة تفاصيل عن الحالة ومدتها وبناءا على ذلك تحتاج لمعالجة نفسيه مرتبطة بطبيعة حالتك ومدى شدتها',\n",
       "    'ما هي المشكله التي تعاني منها']},\n",
       "  {'tag': 'الوسواس',\n",
       "   'patterns': ['ما علاج الوسواس القهري',\n",
       "    ' لدي وسواس من الأمراض وانا كثيرة التفكير فيها',\n",
       "    'منذ عامان شعور بكرة للحياة بعد مشكلة معي ثم بدائت اتوسوس باني اصبت بمرض معين ثم رجعت عن هذة الوسوسة ثم اصبت فعلا بربو الصدر لذالك اشعر دائما بالحزن والمزاجية الشديدة، ما الحل؟',\n",
       "    'لدي وسواس قهري بالافكار والتخيلات ',\n",
       "    'تعاني منذ سنتين من الوسواس القهري ماعلاجه'],\n",
       "   'responses': ['هنالك طرق عدة لعلاج الوسواس القهري كالعلاج السلوكي المعرفي وهو يتم بدون أدوية ولكن في بعض الحالات تستدعي الحالة أدوية .لكن عليك مراجعة اخصائي او طبيب نفسي للتأكد من انك تعاني من اضطراب الوسواس القهري فربما يكون تشخيصك مختلف عن ذلك',\n",
       "    'يعتمد ذلك على فهم الأعراض بشكل شامل والتشخيص الصحيح للحالة ومن ثم ستضمنين ايجاد العلاج المناسب']},\n",
       "  {'tag': 'الرهاب الاجتماعي',\n",
       "   'patterns': ['دايما حاسة اني لوحدي والناس كلها جاية عليا',\n",
       "    'لدي مشاكل أخرى كالقلق والوسواس والرهاب الإجتماعي',\n",
       "    'الخوف من مواجهة ومخاطبة الناس',\n",
       "    'ماذا افعل لكى اتخلص من افكارى السيئه تجاه الاخرين وشكوكى الزائده بها وشعورى الدائم بانى مريضه نفسيا',\n",
       "    'ماسبب عدم الثقه بالاخرين والشعور السلبي',\n",
       "    'مش بعرف اتعامل مع الناس وبتظلم كتير في حياتي من اقرب الناس ليا وبقيت بكرهم',\n",
       "    'أشعر بوتر وخجل عندما أتعامل مع الاخرين'],\n",
       "   'responses': [\"السؤال يعطي بعض الاعراض التي قد تعد طبيعية في مرحلة عمرية معينة و لفترة قصيرة , و لكن اذا كانت هذه الاعراض ممتدة و تؤثر على الاداء الوظيفي للشخص و علاقاته بمجتمعه و تستهلك معظم وقته هنا يجب البحث عن علاج. الاعراض المذكورة لو افترضنا انها الاحساس بالوحدة و الحزن و كراهية الناس و هذا ممتد لفترة طويلة تزيد عن الاسبوعين و تستهلك تفكير و اداء الشخص معظم الوقت فقد يكون ذلك اكتئابا و قد تكون اعراض للقلق. تقلب المزاج قد يكون سمة شخصية و قد يكون عرض لمرض المهم مدة تقلب المزاج و استمراريته, ان يري الشخص انه غير جميل قد يكون عرضا اخر لمرض اخر المهم ما تيرتب على ذلك , يجب مراجعة طبيب نفسي للتشخيص و العلاج'\",\n",
       "    'الباروكستين هو العلاج الانسب للرهاب الاجتماعي والقلق....لكن انصحك بأن تزور طبيبا نفسيا ليقيم حالتك ويصرف لكالعلاج المناسب لحالتك',\n",
       "    'تمرينات اثبات الذات تفيد في مثل حالتك بعد استكمال التشخيص',\n",
       "    \"'انت تعاني من تدني بالثقه بالنفس وتقييمك السي لذاتك فعليك العمل على تقويتها\",\n",
       "    'اذا لم يكن هناك اعراض اخرى فانت تحتاجين الى تمارين التدرب على الثقة بالنفس واثبات الذات',\n",
       "    'قد تعاني من اضطراب الرهاب الاجتماعي، أنصحك بزيارة طبيب نفسي لتقييم حالتك بدقة ووصف العلاج المناسب']},\n",
       "  {'tag': 'الحياة',\n",
       "   'patterns': ['اخاف الجلوس لوحدي في البيت. لدي محاولات بالانتحار. اشعر باليأس و الحزن الشديد',\n",
       "    'لقد وصلت لمرحلة التفكير في الموت على الدوام',\n",
       "    'الخوف من المستقبل وتشويش بالذهن والرغبة في بعض الاحيان التخلص من الحياة '],\n",
       "   'responses': ['تدريبات الثقة بالنفس مفيدة لمثل حالاتك',\n",
       "    'من المفيد لك ان تتدربي على التفكير الايجابي تذكري ( تفائلوا بالخير تجدوه )',\n",
       "    \"تستطيع ان تستفيد من الجوانب الايمانيه في حياتك لرفع الروح المعنوية عندك و التغلب على الاكتئاب وانت بحاجة الى ان تراجع معالجا قريبا منك لكي تستفيد اكثر من التشخيص الدقيق ومن الخدمات العلاجية تبعا لذلك'\",\n",
       "    '  تستطيع ان تستفيد من الجوانب الايمانيه في حياتك لرفع الثقة بالنفس وبالاخرين وذلك سيساعد في التغلب على الاكتئاب والخوف']},\n",
       "  {'tag': 'والاكتئاب',\n",
       "   'patterns': ['اني من كثرة الحزن والتفكير السلبي في اكثر الاوقات ونادرا ما افرح ',\n",
       "    'دائما اشع بالاكتئاب والاحباط والخوف',\n",
       "    'للتخلص من الاكتئاب و الضيق',\n",
       "    'اشعر دائما بل اختناق وأفكر دائماً بي اشياء قد تزعجني أتمنى التخلص من هاذا الشي',\n",
       "    'اعاني من الحالة النفسية السيئة و والاكتئاب و الهم و الحزن',\n",
       "    'انا اشعر بالحزن والوحدة والملل طوال حيات'],\n",
       "   'responses': ['قد تكون هذه اعراض للشخصية الاكتئابية او الاكتئاب او غيره ويعتمد التشخيص على طول المدة الزمنية التي حدثت بها الاعراض اضافة الى تواجد اعراض اخرى لديك',\n",
       "    'من المفيد الاعتناء بتغيير نمط الحياه واسلوب التفكير والعمل على تعديله من خلال تعلم مهارات التعامل مع الضغوط ومهارات التوازن في تخطيط نمط الحياه بين الجوانب الاجتماعية والنفسية الجادة والترفيهية والجوانب الصحية والجوانب الروحانية وفي حال عدم الاستجابة للتحسن يمكن الانسان ان يراجع المعالج بالقرب منه ',\n",
       "    'تذكري ( تفائلوا بالخير تجدوه ) من المفيد لك ان تتدربي على التفكير الايجابي',\n",
       "    'تحتاجين ان تمارسي تمرين الاسترخاء والتفكر الارتقائي\\r\\nكما ان في سن السابعة عشر هو سن تغيرات تحتاجين لتنمية مواهب واكتشاف مهاراتك الشخصيه\\r\\nكما تحتاجين الى تنظيم نمط الحياة اليومية\\r\\nوبعد اسبوع ضعي تقيميا لحالتك وارسليه',\n",
       "    'تستطيع ان تستفيد من الجوانب الايمانيه في حياتك لرفع الثقة بالنفس وبالاخرين وذلك سيساعد في التغلب على الاكتئاب والخوق وانت بحاجة الى ان تراجع معالجا قريبا منك لكي تستفيد اكثر من التشخيص الدقيق ومن الخدمات العلاجية تبعا لذلك',\n",
       "    'تحتاج حالتك الى ان يكون لديك رغبة في التغيير وتحمل المسؤليه عمليا\\r\\nوتحتاج لتنظيم نمط حياتك والمثابرة عليه بشكل متوازن\\r\\nومن المهم مراجعة الطبيب']},\n",
       "  {'tag': 'الذهان التأخري',\n",
       "   'patterns': ['ما هو(الذهان التأخري)؟ وشكرا'],\n",
       "   'responses': ['الذهان: هو مرض يطلق على الحالات العقلية التي تصيب الإنسان والتي يحدث فيها خلل ضمن التفكير المنطقي ، أو في الإدراك الحسي عنده، فهو حالة من فقدان الاتصال مع الواقع، وأبرز ما يميز مرض الذهان بأن الأشخاص المصابين به يصابون بنوبات من الهلوسة، وتمسكهم بمعتقدات وهمية. هناك العديد من الاضطرابات الذهانية التي يمكن ان تصيب الانسان و من اشهرها الفصام العقلي']},\n",
       "  {'tag': 'الفراق',\n",
       "   'patterns': ['اني تركت شخصا احببته كثيرا وانا اعاني من مشكلات في حياتي وانهيار احلامي امامي'],\n",
       "   'responses': ['ستندمل هذه الجراح مع الوقت ولكن المهم الا تصري علي تذكره دائما لان هذا ادمان .فان احببتي العودة الي طبيعتك السابقه عليكي ان تقلعي عنه']},\n",
       "  {'tag': 'صدمة',\n",
       "   'patterns': ['توفي ابي منذ مدة لكني لم استطيع البكاء ابدا فى الاول قلت يمكن تكون من الصدمة لكن الان احاول ان اتذكر كلامه او شيىء يخصه لا استطيع اشعر انه حلم انا اعيش كانه لم يكن في حياتي',\n",
       "    'كيف يستطيع الانسان ان يتخلص من تاثير صدمة نفسيه شديدة اصابته'],\n",
       "   'responses': ['الصدمة تختلف حسب طبيعتها وتختلف حسب تأثيرها كما ان تاثيرها يختلف باختلاف الافراد الواقعة عليهم وحتى يكون تاثيرها اكثر قربا من الصحة النفسية يحتاج الانسان ان يقييم كل ذلك لذا من المهم اعطاء تفاصيل للمعاج ليتمكن من اعطائك الحلول الاكثر فاعلية']},\n",
       "  {'tag': 'دكتور',\n",
       "   'patterns': ['كيف يمكنني التحدث الى طبيب',\n",
       "    'اريد التحدث الى طبيب',\n",
       "    'بمن تنصحني',\n",
       "    'كيف يمكنني اخذ موعد عند طبيب',\n",
       "    'ساعدني فاخذ موعد عند الطبيب'],\n",
       "   'responses': ['بالطبع، الدكتورة عبير متخصصة في مثل هذه الامراض النفسية يمكنك التواصل معها عبر البريد الالكتروني او الاتصال على الرقم : 22 567 456']}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8386d02d",
   "metadata": {},
   "source": [
    "## Step four: Designing a neural network model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5fc7e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "newWords,ourClasses,documentX,documentY= data_processing(get_data())\n",
    "lm = WordNetLemmatizer() #for getting words\n",
    "\n",
    "trainingData = [] # training list array\n",
    "outEmpty = [0] * len(ourClasses)\n",
    "# bow model\n",
    "for idx, doc in enumerate(documentX):\n",
    "    bagOfwords = []\n",
    "    text = lm.lemmatize(doc)\n",
    "    for word in newWords:\n",
    "        bagOfwords.append(1) if word in text else bagOfwords.append(0)\n",
    "\n",
    "    outputRow = list(outEmpty)\n",
    "    outputRow[ourClasses.index(documentY[idx])] = 1\n",
    "    trainingData.append([bagOfwords, outputRow])\n",
    "\n",
    "random.shuffle(trainingData)\n",
    "trainingData = np.array(trainingData, dtype=object)# coverting our data into an array afterv shuffling\n",
    "\n",
    "x = np.array(list(trainingData[:, 0]))# first trainig phase\n",
    "y = np.array(list(trainingData[:, 1]))# second training phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "da1635cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               34688     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 15)                975       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 43,919\n",
      "Trainable params: 43,919\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/200\n",
      "2/2 [==============================] - 1s 24ms/step - loss: 2.7351 - accuracy: 0.0926\n",
      "Epoch 2/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.7071 - accuracy: 0.0185\n",
      "Epoch 3/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 2.6679 - accuracy: 0.0926\n",
      "Epoch 4/200\n",
      "2/2 [==============================] - 0s 17ms/step - loss: 2.6454 - accuracy: 0.0741\n",
      "Epoch 5/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.6335 - accuracy: 0.1296\n",
      "Epoch 6/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.5630 - accuracy: 0.2037\n",
      "Epoch 7/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4888 - accuracy: 0.3148\n",
      "Epoch 8/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.5337 - accuracy: 0.1852\n",
      "Epoch 9/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.4394 - accuracy: 0.3148\n",
      "Epoch 10/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.4259 - accuracy: 0.2407\n",
      "Epoch 11/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.4061 - accuracy: 0.4444\n",
      "Epoch 12/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 2.3830 - accuracy: 0.3889\n",
      "Epoch 13/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.3188 - accuracy: 0.4074\n",
      "Epoch 14/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 2.3264 - accuracy: 0.3704\n",
      "Epoch 15/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 2.2906 - accuracy: 0.4815\n",
      "Epoch 16/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.2506 - accuracy: 0.4444\n",
      "Epoch 17/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.2149 - accuracy: 0.4259\n",
      "Epoch 18/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.1780 - accuracy: 0.4630\n",
      "Epoch 19/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 2.1414 - accuracy: 0.4444\n",
      "Epoch 20/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 2.1086 - accuracy: 0.5556\n",
      "Epoch 21/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.9741 - accuracy: 0.6111\n",
      "Epoch 22/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 2.0786 - accuracy: 0.4630\n",
      "Epoch 23/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 2.0391 - accuracy: 0.4074\n",
      "Epoch 24/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.9827 - accuracy: 0.5000\n",
      "Epoch 25/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 1.8730 - accuracy: 0.5185\n",
      "Epoch 26/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.8001 - accuracy: 0.4815\n",
      "Epoch 27/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 1.8253 - accuracy: 0.4815\n",
      "Epoch 28/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.7570 - accuracy: 0.4630\n",
      "Epoch 29/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.6639 - accuracy: 0.6296\n",
      "Epoch 30/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.6635 - accuracy: 0.5000\n",
      "Epoch 31/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.5233 - accuracy: 0.6481\n",
      "Epoch 32/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.6442 - accuracy: 0.6111\n",
      "Epoch 33/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 1.4324 - accuracy: 0.6667\n",
      "Epoch 34/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.4883 - accuracy: 0.6296\n",
      "Epoch 35/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.4774 - accuracy: 0.7037\n",
      "Epoch 36/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.3919 - accuracy: 0.6852\n",
      "Epoch 37/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 1.3300 - accuracy: 0.7037\n",
      "Epoch 38/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.3569 - accuracy: 0.7407\n",
      "Epoch 39/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.2534 - accuracy: 0.7037\n",
      "Epoch 40/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.2799 - accuracy: 0.6296\n",
      "Epoch 41/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 1.3601 - accuracy: 0.6667\n",
      "Epoch 42/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 1.1326 - accuracy: 0.7963\n",
      "Epoch 43/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 1.0538 - accuracy: 0.7963\n",
      "Epoch 44/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0893 - accuracy: 0.8148\n",
      "Epoch 45/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 1.0547 - accuracy: 0.7963\n",
      "Epoch 46/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 1.0024 - accuracy: 0.8333\n",
      "Epoch 47/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.9235 - accuracy: 0.8519\n",
      "Epoch 48/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9007 - accuracy: 0.8519\n",
      "Epoch 49/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.8602 - accuracy: 0.8519\n",
      "Epoch 50/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.9949 - accuracy: 0.8148\n",
      "Epoch 51/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.9572 - accuracy: 0.8148\n",
      "Epoch 52/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8119 - accuracy: 0.8333\n",
      "Epoch 53/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.9500 - accuracy: 0.7963\n",
      "Epoch 54/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.8244 - accuracy: 0.8704\n",
      "Epoch 55/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7680 - accuracy: 0.9074\n",
      "Epoch 56/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.7721 - accuracy: 0.8333\n",
      "Epoch 57/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.8261 - accuracy: 0.8148\n",
      "Epoch 58/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.7205 - accuracy: 0.8889\n",
      "Epoch 59/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.7286 - accuracy: 0.8704\n",
      "Epoch 60/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.6505 - accuracy: 0.9074\n",
      "Epoch 61/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.6551 - accuracy: 0.8519\n",
      "Epoch 62/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6325 - accuracy: 0.9074\n",
      "Epoch 63/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.6573 - accuracy: 0.8704\n",
      "Epoch 64/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.6754 - accuracy: 0.8333\n",
      "Epoch 65/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5311 - accuracy: 0.8704\n",
      "Epoch 66/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.5780 - accuracy: 0.9074\n",
      "Epoch 67/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5474 - accuracy: 0.9074\n",
      "Epoch 68/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.6136 - accuracy: 0.8889\n",
      "Epoch 69/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4631 - accuracy: 0.9444\n",
      "Epoch 70/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.4208 - accuracy: 0.9259\n",
      "Epoch 71/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5125 - accuracy: 0.8704\n",
      "Epoch 72/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.4636 - accuracy: 0.9074\n",
      "Epoch 73/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.5104 - accuracy: 0.9444\n",
      "Epoch 74/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4177 - accuracy: 0.9444\n",
      "Epoch 75/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.5337 - accuracy: 0.8889\n",
      "Epoch 76/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4908 - accuracy: 0.8889\n",
      "Epoch 77/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.4335 - accuracy: 0.9630\n",
      "Epoch 78/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.4614 - accuracy: 0.9259\n",
      "Epoch 79/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.4344 - accuracy: 0.9074\n",
      "Epoch 80/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3718 - accuracy: 0.9444\n",
      "Epoch 81/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3717 - accuracy: 0.9074\n",
      "Epoch 82/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3827 - accuracy: 0.9444\n",
      "Epoch 83/200\n",
      "2/2 [==============================] - 0s 14ms/step - loss: 0.3491 - accuracy: 0.9815\n",
      "Epoch 84/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3950 - accuracy: 0.9259\n",
      "Epoch 85/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.3353 - accuracy: 0.9815\n",
      "Epoch 86/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3560 - accuracy: 0.9074\n",
      "Epoch 87/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3028 - accuracy: 0.9815\n",
      "Epoch 88/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2930 - accuracy: 0.9444\n",
      "Epoch 89/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3011 - accuracy: 0.9815\n",
      "Epoch 90/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.3259 - accuracy: 0.9815\n",
      "Epoch 91/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3304 - accuracy: 0.9815\n",
      "Epoch 92/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2917 - accuracy: 0.9630\n",
      "Epoch 93/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.2159 - accuracy: 0.9630\n",
      "Epoch 94/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3913 - accuracy: 0.9074\n",
      "Epoch 95/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.3437 - accuracy: 0.9259\n",
      "Epoch 96/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2579 - accuracy: 0.9815\n",
      "Epoch 97/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.3620 - accuracy: 0.9074\n",
      "Epoch 98/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.3155 - accuracy: 0.9444\n",
      "Epoch 99/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2642 - accuracy: 0.9630\n",
      "Epoch 100/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2338 - accuracy: 0.9630\n",
      "Epoch 101/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2875 - accuracy: 0.9444\n",
      "Epoch 102/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1967 - accuracy: 0.9815\n",
      "Epoch 103/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2805 - accuracy: 0.9444\n",
      "Epoch 104/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2182 - accuracy: 0.9444\n",
      "Epoch 105/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2223 - accuracy: 0.9444\n",
      "Epoch 106/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2119 - accuracy: 0.9630\n",
      "Epoch 107/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2039 - accuracy: 0.9815\n",
      "Epoch 108/200\n",
      "2/2 [==============================] - 0s 2ms/step - loss: 0.2272 - accuracy: 0.9630\n",
      "Epoch 109/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.2289 - accuracy: 0.9630\n",
      "Epoch 110/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1822 - accuracy: 0.9815\n",
      "Epoch 111/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1972 - accuracy: 0.9630\n",
      "Epoch 112/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1844 - accuracy: 0.9815\n",
      "Epoch 113/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1891 - accuracy: 0.9815\n",
      "Epoch 114/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2359 - accuracy: 0.9259\n",
      "Epoch 115/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2307 - accuracy: 0.9259\n",
      "Epoch 116/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.2444 - accuracy: 0.9444\n",
      "Epoch 117/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1994 - accuracy: 0.9815\n",
      "Epoch 118/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.2360 - accuracy: 0.9630\n",
      "Epoch 119/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.2103 - accuracy: 0.9815\n",
      "Epoch 120/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1809 - accuracy: 0.9630\n",
      "Epoch 121/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.2376 - accuracy: 0.9259\n",
      "Epoch 122/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1757 - accuracy: 0.9630\n",
      "Epoch 123/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.2493 - accuracy: 0.9444\n",
      "Epoch 124/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1763 - accuracy: 0.9630\n",
      "Epoch 125/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1349 - accuracy: 0.9815\n",
      "Epoch 126/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1219 - accuracy: 0.9815\n",
      "Epoch 127/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1593 - accuracy: 0.9815\n",
      "Epoch 128/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1324 - accuracy: 0.9815\n",
      "Epoch 129/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1299 - accuracy: 0.9815\n",
      "Epoch 130/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2077 - accuracy: 0.9444\n",
      "Epoch 131/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1513 - accuracy: 0.9815\n",
      "Epoch 132/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1320 - accuracy: 0.9815\n",
      "Epoch 133/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1969 - accuracy: 0.9630\n",
      "Epoch 134/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1478 - accuracy: 0.9815\n",
      "Epoch 135/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1474 - accuracy: 0.9815\n",
      "Epoch 136/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.9815\n",
      "Epoch 137/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1684 - accuracy: 0.9815\n",
      "Epoch 138/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1382 - accuracy: 0.9815\n",
      "Epoch 139/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1779 - accuracy: 0.9630\n",
      "Epoch 140/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1462 - accuracy: 0.9630\n",
      "Epoch 141/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.1441 - accuracy: 0.9630\n",
      "Epoch 142/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.1304 - accuracy: 0.9815\n",
      "Epoch 143/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1213 - accuracy: 0.9630\n",
      "Epoch 144/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1165 - accuracy: 0.9815\n",
      "Epoch 145/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1380 - accuracy: 0.9444\n",
      "Epoch 146/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0981 - accuracy: 0.9815\n",
      "Epoch 147/200\n",
      "2/2 [==============================] - 0s 15ms/step - loss: 0.1188 - accuracy: 0.9630\n",
      "Epoch 148/200\n",
      "2/2 [==============================] - 0s 4ms/step - loss: 0.1189 - accuracy: 0.9815\n",
      "Epoch 149/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0888 - accuracy: 0.9815\n",
      "Epoch 150/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1504 - accuracy: 0.9630\n",
      "Epoch 151/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.2329 - accuracy: 0.9444\n",
      "Epoch 152/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1338 - accuracy: 0.9815\n",
      "Epoch 153/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1175 - accuracy: 0.9630\n",
      "Epoch 154/200\n",
      "2/2 [==============================] - 0s 12ms/step - loss: 0.1134 - accuracy: 0.9815\n",
      "Epoch 155/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1001 - accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 156/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0870 - accuracy: 0.9815\n",
      "Epoch 157/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0983 - accuracy: 0.9815\n",
      "Epoch 158/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1204 - accuracy: 0.9630\n",
      "Epoch 159/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0854 - accuracy: 0.9815\n",
      "Epoch 160/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1062 - accuracy: 0.9815\n",
      "Epoch 162/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0938 - accuracy: 0.9815\n",
      "Epoch 163/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0957 - accuracy: 0.9630\n",
      "Epoch 164/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.1520 - accuracy: 0.9444\n",
      "Epoch 165/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0725 - accuracy: 0.9815\n",
      "Epoch 166/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0820 - accuracy: 0.9630\n",
      "Epoch 167/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9815\n",
      "Epoch 168/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0904 - accuracy: 0.9815\n",
      "Epoch 169/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1093 - accuracy: 0.9815\n",
      "Epoch 170/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0970 - accuracy: 0.9815\n",
      "Epoch 171/200\n",
      "2/2 [==============================] - 0s 3ms/step - loss: 0.1006 - accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1561 - accuracy: 0.9630\n",
      "Epoch 173/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0833 - accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0836 - accuracy: 0.9815\n",
      "Epoch 175/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1190 - accuracy: 0.9815\n",
      "Epoch 176/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0651 - accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.1266 - accuracy: 0.9815\n",
      "Epoch 178/200\n",
      "2/2 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.9815\n",
      "Epoch 179/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0788 - accuracy: 0.9630\n",
      "Epoch 180/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1035 - accuracy: 0.9444\n",
      "Epoch 181/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0767 - accuracy: 0.9815\n",
      "Epoch 182/200\n",
      "2/2 [==============================] - 0s 5ms/step - loss: 0.0665 - accuracy: 0.9815\n",
      "Epoch 183/200\n",
      "2/2 [==============================] - 0s 10ms/step - loss: 0.0819 - accuracy: 0.9815\n",
      "Epoch 184/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9630\n",
      "Epoch 185/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0963 - accuracy: 0.9815\n",
      "Epoch 186/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1154 - accuracy: 0.9630\n",
      "Epoch 187/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0709 - accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1023 - accuracy: 0.9815\n",
      "Epoch 189/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0548 - accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.1003 - accuracy: 0.9630\n",
      "Epoch 191/200\n",
      "2/2 [==============================] - 0s 6ms/step - loss: 0.0687 - accuracy: 0.9815\n",
      "Epoch 192/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0575 - accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "2/2 [==============================] - 0s 7ms/step - loss: 0.0631 - accuracy: 0.9815\n",
      "Epoch 194/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0760 - accuracy: 0.9815\n",
      "Epoch 195/200\n",
      "2/2 [==============================] - 0s 13ms/step - loss: 0.0677 - accuracy: 0.9815\n",
      "Epoch 196/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0686 - accuracy: 0.9815\n",
      "Epoch 197/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0730 - accuracy: 0.9815\n",
      "Epoch 198/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.0690 - accuracy: 0.9815\n",
      "Epoch 199/200\n",
      "2/2 [==============================] - 0s 9ms/step - loss: 0.0528 - accuracy: 0.9815\n",
      "Epoch 200/200\n",
      "2/2 [==============================] - 0s 8ms/step - loss: 0.1010 - accuracy: 0.9815\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x25133837f70>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iShape = (len(x[0]),)\n",
    "oShape = len(y[0])\n",
    "# parameter definition\n",
    "ourNewModel = Sequential()\n",
    "# In the case of a simple stack of layers, a Sequential model is appropriate\n",
    "\n",
    "# Dense function adds an output layer\n",
    "ourNewModel.add(Dense(128, input_shape=iShape, activation=\"relu\"))\n",
    "# The activation function in a neural network is in charge of converting the node's summed weighted input into activation of the node or output for the input in question\n",
    "ourNewModel.add(Dropout(0.5))\n",
    "# Dropout is used to enhance visual perception of input neurons\n",
    "ourNewModel.add(Dense(64, activation=\"relu\"))\n",
    "ourNewModel.add(Dropout(0.3))\n",
    "ourNewModel.add(Dense(oShape, activation = \"softmax\"))\n",
    "\n",
    "# Below line improves the numerical stability and pushes the computation of the probability distribution into the categorical crossentropy loss function.\n",
    "ourNewModel.compile(loss='categorical_crossentropy', optimizer=tensorF.keras.optimizers.Adam(lr=0.01), metrics=[\"accuracy\"])\n",
    "# Output the model in summary\n",
    "print(ourNewModel.summary())\n",
    "# Whilst training your Nural Network, you have the option of making the output verbose or simple.\n",
    "ourNewModel.fit(x, y, epochs=200, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b71d43cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = ourNewModel.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "ourNewModel.save_weights('model.h5') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1124fb8",
   "metadata": {},
   "source": [
    "## Step five: Building useful features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "893891a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ourText(text):\n",
    "    lm = WordNetLemmatizer()\n",
    "    newtkns = nltk.word_tokenize(text)\n",
    "    newtkns = [lm.lemmatize(word) for word in newtkns]\n",
    "    return newtkns\n",
    "\n",
    "def wordBag(text, vocab):\n",
    "    newtkns = ourText(text)\n",
    "    bagOwords = [0] * len(vocab)\n",
    "    for w in newtkns:\n",
    "        for idx, word in enumerate(vocab):\n",
    "            if word == w:\n",
    "                bagOwords[idx] = 1\n",
    "    return np.array(bagOwords)\n",
    "\n",
    "def Pclass(text, vocab, labels,model):\n",
    "    bagOwords = wordBag(text, vocab)\n",
    "    ourResult = model.predict(np.array([bagOwords]))[0]\n",
    "    newThresh = 0.2\n",
    "    yp = [[idx, res] for idx, res in enumerate(ourResult) if res > newThresh]\n",
    "\n",
    "    yp.sort(key=lambda x: x[1], reverse=True)\n",
    "    newList = []\n",
    "    for r in yp:\n",
    "        newList.append(labels[r[0]])\n",
    "    return newList\n",
    "\n",
    "def getRes(firstlist, fJson):\n",
    "    tag = firstlist[0]\n",
    "    listOfIntents = fJson[\"Intents\"]\n",
    "    for i in listOfIntents:\n",
    "        if i[\"tag\"] == tag:\n",
    "            ourResult = random.choice(i[\"responses\"])\n",
    "            break\n",
    "    return ourResult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59c9ba9",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08c5e8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(text,model):\n",
    "    data=get_data()\n",
    "    newWords, ourClasses,_,__=data_processing(data)\n",
    "    intents = Pclass(text, newWords, ourClasses,model)\n",
    "    return getRes(intents, data)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90da089f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' مرحبا بيك، ماهو سؤالك اليوم ؟'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_answer(\"سلام\",ourNewModel)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
